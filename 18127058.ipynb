{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T CHANGE this part: import libraries\n",
    "import numpy as np\n",
    "import scipy\n",
    "import json\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "import re\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess: converting text to lowercase, coverting number, tokenization, removing stopword, stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. preprocess: converting text to lowercase, coverting number, tokenization, removing stopword, stemming\n",
    "def preprocess(text):\n",
    "   # converting text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # splitting text to words\n",
    "    corpus = word_tokenize(text)\n",
    "\n",
    "    # initialize stemming\n",
    "    porter = PorterStemmer()\n",
    "\n",
    "    # initialize stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # removing stop words and stemming and convert number to 'num'\n",
    "    res = []\n",
    "    for w in corpus:\n",
    "        if not w in stop_words:\n",
    "            if w.isdigit():\n",
    "                res.append('num')\n",
    "            else:\n",
    "                res.append(porter.stem(w))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a matrix A with size (document_size, 1 + vocab_size) and label matrix b with size (document_size, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAb(xs, ys):\n",
    "    col1 = np.ones(xs.shape[0], dtype='float')\n",
    "    A = np.insert(xs, 0, col1, axis=1)\n",
    "    b = np.array(ys, dtype='float').reshape(len(ys), 5)\n",
    "    return A, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data set of file 'train.json' v√† 'valid.jason'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T CHANGE this part: read data path\n",
    "# train_set_path, valid_set_path, random_number = input().split()\n",
    "train_set_path, valid_set_path = 'train.json', 'valid.json'\n",
    "random_number = 89\n",
    "\n",
    "# Input data for label and text of train\n",
    "label = []\n",
    "reviewText = []\n",
    "res = []\n",
    "with open(train_set_path) as json_file:\n",
    "    data = json.load(json_file)\n",
    "    for p in data:\n",
    "        \n",
    "        # initializing label vector\n",
    "        rate = [0, 0, 0, 0, 0]\n",
    "        rate[int(p['overall'])-1] = 1\n",
    "        label.append(rate)\n",
    "        reviewText.append(p['reviewText'])\n",
    "        \n",
    "        # initializing word document vector\n",
    "        res += preprocess(p['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data for label and text of valid\n",
    "label_valid = []\n",
    "reviewText_valid = []\n",
    "res_valid = []\n",
    "with open(valid_set_path) as json_file:\n",
    "    data = json.load(json_file)\n",
    "    for p in data:\n",
    "        \n",
    "        # initializing label vector\n",
    "        rate = [0, 0, 0, 0, 0]\n",
    "        rate[int(p['overall'])-1] = 1\n",
    "        label_valid.append(rate)\n",
    "        \n",
    "        # initializing word document vector\n",
    "        reviewText_valid.append(p['reviewText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dictionary for all of key have the value 0, size of dictionary and the number of document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing dictionary\n",
    "dictionary = {w: 0 for w in res}\n",
    "\n",
    "# Vocab_size\n",
    "vocab_size = len(dictionary)\n",
    "\n",
    "# The number of document\n",
    "document_size = len(reviewText)\n",
    "\n",
    "# The number of valid document used for testing\n",
    "document_valid_size = len(reviewText_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Embedding: hitogram matrix:\n",
    "ai = number of times word i appears in the document\n",
    "$$ h = \\frac{a}{1^{T}a} $$  h is word frequency or histogram vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing histogram matrix of training data set with size (document_size, vocab_size)\n",
    "histogram_matrix = np.empty((document_size, vocab_size), dtype='float')\n",
    "for i in range(document_size):\n",
    "    doc = dictionary.copy()\n",
    "    review = preprocess(reviewText[i])\n",
    "    \n",
    "    # Creating word count vector\n",
    "    for word in review:\n",
    "        doc[word] += 1\n",
    "\n",
    "    # Creating the histogram vector\n",
    "    sum_doc = sum(doc.values())\n",
    "    histogram = [doc[w]/sum_doc for w in doc]\n",
    "\n",
    "    histogram_matrix[i] = histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing histogram matrix of valid data set with size (document_valid_size, vocab_size)\n",
    "histogram_matrix_valid = np.empty((document_valid_size, vocab_size), dtype='float')\n",
    "for i in range(document_valid_size):\n",
    "    doc = dictionary.copy()\n",
    "    review = preprocess(reviewText_valid[i])\n",
    "    \n",
    "    # Creating word count vector\n",
    "    for word in review:\n",
    "        if word in dictionary.keys():\n",
    "            doc[word] += 1\n",
    "\n",
    "    # Creating the histogram vector\n",
    "    sum_doc = sum(doc.values())\n",
    "    histogram = [doc[w]/sum_doc for w in doc]\n",
    "\n",
    "    histogram_matrix_valid[i] = histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classifier using linear regression: **$$\\hat{x} = (A^{T}A)^{-1}A^{T}b = A^{+}b$$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, b = getAb(histogram_matrix, label)\n",
    "x_hat = np.linalg.pinv(A) @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Accuracy (for metric): $$ acc = \\frac{\\sum(right)}{\\sum(total)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['great', 'photographi', 'class', ',', 'sadli', 'bought', 'wrong', 'kind', 'class', 'ask', '.', 'good', 'practic', 'paper']\n",
      "M2 - 0.52\n"
     ]
    }
   ],
   "source": [
    "# Adding a column of 1 to matrix\n",
    "col1 = np.ones(histogram_matrix_valid.shape[0], dtype='float')\n",
    "A_valid = np.insert(histogram_matrix_valid, 0, col1, axis=1)\n",
    "\n",
    "acc = 0.0\n",
    "for index in range(document_valid_size):\n",
    "    # Using softmax to return appropriate label\n",
    "    final = scipy.special.softmax(A_valid[index][:] @ x_hat)\n",
    "    \n",
    "    # Counting the right \n",
    "    if(np.argmax(final) == np.argmax(label_valid[index])):\n",
    "        acc += 1\n",
    "\n",
    "# Accuracy = right / total\n",
    "acc /= document_valid_size\n",
    "\n",
    "print(preprocess(reviewText_valid[random_number]))\n",
    "print(f\"M2 - {acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
